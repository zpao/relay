"use strict";(self.webpackChunk=self.webpackChunk||[]).push([[70077],{92428:e=>{e.exports=JSON.parse('{"blogPosts":[{"id":"/2023/10/24/how-relay-enables-optimal-data-fetching","metadata":{"permalink":"/relay/blog/2023/10/24/how-relay-enables-optimal-data-fetching","source":"@site/blog/2023-10-24-how-relay-enables-optimal-data-fetching.md","title":"How Relay Enables Optimal Data Fetching","description":"Exploring the tradoeffs that most data fetching strategies are forced to make, and how Relay allows you to have your cake and eat it too.","date":"2023-10-24T00:00:00.000Z","formattedDate":"October 24, 2023","tags":[],"readingTime":4.31,"hasTruncateMarker":false,"authors":[{"name":"Jordan Eldredge"}],"frontMatter":{"title":"How Relay Enables Optimal Data Fetching","author":"Jordan Eldredge","tags":[],"description":"Exploring the tradoeffs that most data fetching strategies are forced to make, and how Relay allows you to have your cake and eat it too.","hide_table_of_contents":false},"nextItem":{"title":"Relay v15.0","permalink":"/relay/blog/2023/03/30/relay-15"}},"content":"Relay\u2019s approach to application authorship enables a unique combination of\\noptimal runtime performance and application maintainability. In this post I\u2019ll\\ndescribe the tradeoffs most apps are forced to make with their data fetching and\\nthen describe how Relay\u2019s approach allows you to sidestep these tradeoffs and\\nachieve an optimal outcome across multiple tradeoff dimensions.\\n\\n---\\n\\nIn component-based UI systems such as React, one important decision to make is\\nwhere in your UI tree you fetch data. While data fetching can be done at any\\npoint in the UI tree, in order to understand the tradeoffs at play, let\u2019s\\nconsider the two extremes:\\n\\n- Leaf node: Fetch data directly within each component that uses data\\n- Root node: Fetch all data at the root of your UI and thread it down to leaf\\n  nodes using prop drilling\\n\\nWhere in the UI tree you fetch data impacts multiple dimensions of the\\nperformance and maintainability of your application. Unfortunately, with naive\\ndata fetching, neither extreme is optimal for all dimensions. Let\u2019s look at\\nthese dimensions and consider which improve as you move data fetching closer to\\nthe leaves, vs. which improve as you move data fetching closer to the root.\\n\\n### Loading experience\\n\\n- \ud83d\udeab Leaf node: If individual nodes fetch data, you will end up with request\\n  cascades where your UI needs to make multiple request roundtrips in series\\n  (waterfalls) since each layer of the UI is blocked on its parent layer\\n  rendering. Additionally, if multiple components happen to use the same data,\\n  you will end up fetching the same data multiple times\\n- \u2705 Root node: If all your data is fetched at the root, you will make single\\n  request and render the whole UI without any duplicate data or cascading\\n  requests\\n\\n### Suspense cascades\\n\\n- \ud83d\udeab Leaf node: If each individual component needs to fetch data separately,\\n  each component will suspend on initial render. With the current implementation\\n  of React, unsuspending results in rerendering from the nearest parent suspense\\n  boundary. This means you will have to reevaluate product component code O(n)\\n  times during initial load, where n is the depth of the tree.\\n- \u2705 Root node: If all your data is fetched at the root, you will suspend a\\n  single time and evaluate product component code only once.\\n\\n### Composability\\n\\n- \u2705 Leaf node: Using an existing component in a new place is as easy as\\n  rendering it. Removing a component is as simple as not-rendering it. Similarly\\n  adding/removing data dependencies can be done fully locally.\\n- \ud83d\udeab Root node: Adding an existing component as a child of another component\\n  requires updating every query that includes that component to fetch the new\\n  data and then threading the new data through all intermediate layers.\\n  Similarly, removing a component requires tracing those data dependencies back\\n  to each root component and determining if the component you removed was that\\n  data\u2019s last remaining consumer. The same dynamics apply to adding/removing new\\n  data to an existing component.\\n\\n### Granular updates\\n\\n- \u2705 Leaf node: When data changes, each component reading that data can\\n  individually rerender, avoiding the need to rerender unaffected components.\\n- \ud83d\udeab Root node: Since all data originates at the root, when any data updates it\\n  always forces the root component to update forcing an expensive rerender of\\n  the entire component tree.\\n\\n## Relay\\n\\nRelay leverages GraphQL fragments and a compiler build step to offer a more\\noptimal alternative. In an app that uses Relay, each component defines a GraphQL\\nfragment which declares the data that it needs. This includes both the concrete\\nvalues the component will render as well as the fragments (referenced by name)\\nof each direct child component it will render.\\n\\nAt build time, the Relay compiler collects these fragments and builds a single\\nquery for each root node in your application. Let\u2019s look at how this approach\\nplays out for each of the dimensions described above:\\n\\n- \u2705 Loading experience - The compiler generated query fetches all data needed\\n  for the surface in a single roundtrip\\n- \u2705 Suspense cascades - Since all data is fetched in a single request, we only\\n  suspend once, and it\u2019s right at the root of the tree\\n- \u2705 Composability - Adding/removing data from a component, including the\\n  fragment data needed to render a child component, can be done locally within a\\n  single component. The compiler takes care of updating all impacted root\\n  queries\\n- \u2705 Granular updates - Because each component defines a fragment, Relay knows\\n  exactly which data is consumed by each component. This lets relay perform\\n  optimal updates where the minimal set of components are rerendered when data\\n  changes\\n\\n## Summary\\n\\nAs you can see, Relay\u2019s use of a declarative composable data fetching language\\n(GraphQL), combined a compiler step, allows us to achieve optimal outcomes\\nacross all of the tradeoff dimensions outlined above:\\n\\n|                    | Leaf node | Root node | GraphQL/Relay |\\n| ------------------ | --------- | --------- | ------------- |\\n| Loading experience | \ud83d\udeab        | \u2705        | \u2705            |\\n| Suspense cascades  | \ud83d\udeab        | \u2705        | \u2705            |\\n| Composability      | \u2705        | \ud83d\udeab        | \u2705            |\\n| Granular updates   | \u2705        | \ud83d\udeab        | \u2705            |"},{"id":"/2023/03/30/relay-15","metadata":{"permalink":"/relay/blog/2023/03/30/relay-15","source":"@site/blog/2023-03-30-relay-15.mdx","title":"Relay v15.0","description":"The Relay team is happy to announce the release of Relay v15. While this release is a major version bump and includes a couple of breaking changes, we expect that most users will be unaffected and will experience a seamless upgrade. You can find the full list of changes in the v15 Release Notes.","date":"2023-03-30T00:00:00.000Z","formattedDate":"March 30, 2023","tags":[],"readingTime":3.315,"hasTruncateMarker":false,"authors":[{"name":"The Relay Team"}],"frontMatter":{"title":"Relay v15.0","author":"The Relay Team","hide_table_of_contents":false},"prevItem":{"title":"How Relay Enables Optimal Data Fetching","permalink":"/relay/blog/2023/10/24/how-relay-enables-optimal-data-fetching"},"nextItem":{"title":"Resilient Relay Applications","permalink":"/relay/blog/2023/01/03/resilient-relay-apps"}},"content":"The Relay team is happy to announce the release of Relay v15. While this release is a major version bump and includes a couple of breaking changes, we expect that most users will be unaffected and will experience a seamless upgrade. You can find the full list of changes in the [v15 Release Notes](https://github.com/facebook/relay/releases/tag/v15.0.0).\\n\\n## What\'s new in Relay 15?\\n\\n### Support for `@refetchable` on interfaces\\n\\nPreviously it wasn\'t possible to add the `@refetchable` directive on fragment definitions on server interface types.\\n\\n```\\n// schema.graphql\\n\\ninterface RefetchableInterfaceFoo @fetchable(field_name: \\"id\\") {\\n    id: ID!\\n}\\n\\nextend type Query {\\n  fetch__RefetchableInterfaceFoo(id: ID!): RefetchableInterfaceFoo\\n}\\n\\n// fragment\\n\\nfragment RefetchableFragmentFoo on RefetchableInterfaceFoo\\n  @refetchable(queryName: \\"RefetchableFragmentFooQuery\\") {\\n  id\\n}\\n```\\n\\n### Persisted query improvements\\n\\nIf you use URL-based persisted queries, you can now specify custom headers to send with the request that persists the query. For example, this can be used to send auth headers to your query persistence URL endpoint.\\n\\n```js\\npersistConfig: {\\n  url: \'example.com/persist\',\\n  headers: {\\n    Authorization: \'bearer TOKEN\'\\n  }\\n}\\n```\\n\\nFor file-based persisted queries, we added a new feature flag, `compact_query_text`, that removes all whitespace from the persisted query text. This can make the file more than 60% smaller. This new feature flag can be enabled within your Relay config file.\\n\\n```js\\npersistConfig: {\\n  file: \'path/to/file.json\',\\n  algorithm: \'SHA256\'\\n},\\nfeatureFlags: {\\n  compact_query_text: true\\n}\\n```\\n\\n### Typesafe updates now support missing field handlers\\n\\nTypesafe updaters now support missing field handlers. Previously, if you selected `node(id: 4) { ... on User { name, __typename } }` in a typesafe updater, but that user was fetched in a different way (e.g. with `best_friend { name }`), you would not be able to access and mutate that user using the typesafe updater.\\n\\nIn this release, we add support for missing field handlers in typesafe updaters, meaning that if a missing field handler is set up for node (as in [this example](https://relay.dev/docs/next/guided-tour/reusing-cached-data/filling-in-missing-data/#internaldocs-banner)), you will be able to update the user\'s name with this missing field handler.\\n\\nIn order to support this, the signature of [missing field handlers](https://relay.dev/docs/guided-tour/reusing-cached-data/filling-in-missing-data) has been changed. The `record` argument to the handler used to recieve a `Record` type (which is an untyped grab-bag of data). It now receives a `ReadOnlyRecordProxy`. Furthermore, the field argument of type `NormalizationLinkedField` is now `CommonLinkedField`, which is a type containing the properties found in both `ReaderLinkedField` and `NormalizationLinkedField`.\\n\\n### Flow type improvements\\n\\nFlow users will now get types inferred from `graphql` literals with more Relay APIs. No longer do Flow users need to explicitly type the return value of the `usePreloadedQuery`, `useQueryLoader`, `useRefetchableFragment`, `usePaginationFragment`, and `useBlockingPaginationFragment` API methods.\\n\\n### Relay Resolver improvements\\n\\nA significant portion of our development effort since our last release has gone into improving [Relay Resolvers](https://relay.dev/docs/guides/relay-resolvers) (a mechanism for exposing derived data in the graph). It is worth noting that Relay Resolvers are still experimental and API changes might occur in the future.\\n\\n#### Terser docblock tags\\n\\nThe annotation for Relay Resolver functions has been simplified. In many scenarios you can now use the `ParentType.field_name: ReturnType` syntax to define what new field your Relay Resolver exposes.\\n\\nBefore:\\n\\n```js\\n/**\\n * @RelayResolver\\n * @onType User\\n * @fieldName favorite_page\\n * @rootFragment myRootFragment\\n */\\n```\\n\\nAfter:\\n\\n```js\\n/**\\n * @RelayResolver User.favorite_page: Page\\n * @rootFragment myRootFragment\\n */\\n```\\n\\nIn the above example, the `Page` type is a schema type. If your Relay Resolver doesn\'t return a schema type, you can use fixed `RelayResolverValue` value as your return type\\n\\n```js\\n/**\\n * @RelayResolver User.best_friend: RelayResolverValue\\n * @rootFragment myRootFragment\\n */\\n```\\n\\n#### Define multiple resolvers per file\\n\\nPrior to this release we only allowed a single Relay Resolver per file and required the Relay Resolver function to be the default export. In Relay 15 you\'re now able to define multiple Relay Resolvers per file and use named exports.\\n\\n```js\\n/**\\n * @RelayResolver User.favorite_page: Page\\n * @rootFragment favoritePageFragment\\n */\\nfunction usersFavoritePage(){\\n  ...\\n}\\n\\n/**\\n * @RelayResolver User.best_friend: RelayResolverValue\\n * @rootFragment bestFriendFragment\\n */\\nfunction usersBestFriend(){\\n  ...\\n}\\n\\nmodule.exports = {\\n  usersFavoritePage,\\n  usersBestFriend\\n}\\n```\\n\\nHappy Querying!"},{"id":"/2023/01/03/resilient-relay-apps","metadata":{"permalink":"/relay/blog/2023/01/03/resilient-relay-apps","source":"@site/blog/2023-01-03-resilient-relay-apps.mdx","title":"Resilient Relay Applications","description":"Resilient Relay Applications","date":"2023-01-03T00:00:00.000Z","formattedDate":"January 3, 2023","tags":[],"readingTime":21.655,"hasTruncateMarker":false,"authors":[{"name":"Ernie Turner"}],"frontMatter":{"title":"Resilient Relay Applications","author":"Ernie Turner","description":"Resilient Relay Applications","hide_table_of_contents":false},"prevItem":{"title":"Relay v15.0","permalink":"/relay/blog/2023/03/30/relay-15"},"nextItem":{"title":"Introducing the new Relay compiler","permalink":"/relay/blog/2021/12/08/introducing-the-new-relay-compiler"}},"content":"import Image from \'@site/components/Image\';\\n\\n:::tip Guest Post\\n\\nThis is a guest post written by Ernie Turner, a Staff Engineer at Coinbase. Coinbase has thoroughly adopted Relay in their applications and is a strong ally of the Relay Team. Last year they helped co-develop the [Relay VSCode extension](https://marketplace.visualstudio.com/items?itemName=meta.relay). Ernie has agreed to share this internal enginnering blog post with us.\\n\\n:::\\n\\n## How to provide the best experience for customers during service disruptions\\n\\nIn a perfect world, none of the services at Coinbase would suffer outages, and all fields in our GraphQL schema would resolve correctly all the time. As this isn\'t practical, Coinbase applications should be resilient to downtime and minimize the impact on customers: a single service suffering downtime should not prevent users from using or interacting with an entire app. However, it\'s also important that we convey issues to users when our applications aren\'t working as expected. Showing error messages that convey downtime with retry buttons is a better experience than confusing users with missing content or UI they can\'t interact with.\\n\\nThis post will cover the common patterns and best practices for dealing with missing data in a Relay application.\\n\\n## Screen Architecture and Error Boundaries\\n\\nBefore we discuss handling service downtime and failures in GraphQL queries, let\'s first discuss broader screen architecture and how React Error Boundaries can help create a better user experience when used correctly.\\n\\nLike most things in life, Error Boundaries should be used in moderation. Let\'s look at a common screen in the Coinbase Retail app.\\n\\n<Image src={require(\'./images/2023-01-03-resilient-relay-apps-asset-screen.png\')} width=\\"35%\\" title=\\"Asset detail screen\\"/>\\n\\nAny section in the above screen could fail to get the data required to render, but it\'s how we approach these failures that differentiates what experience a user has with our app. For example, only using a single screen-level ErrorBoundary for any failure causes the app to be unusable when any error occurs, regardless of the significance of that error. In contrast, wrapping each component in its own ErrorBoundary can create just as bad of an experience. Lastly, omitting components with errors entirely is as bad as the other two options. There is no one-size-fits-all approach, so let\'s break down each of these and explain why they create poor user experiences.\\n\\n### Full Screen Error\\n\\n<Image src={require(\'./images/2023-01-03-resilient-relay-apps-full-app-error.png\')} width=\\"35%\\" title=\\"Full Screen Error\\" />\\n\\nThe UI above is Coinbase\'s full-screen error fallback that is displayed if a service is experiencing disruptions and we couldn\'t get the data necessary to render the components on this screen. In certain situations, this actually creates a good user experience. We may not be giving the user detailed information as to what happened, but in most situations providing the technical cause is not possible, nor would it improve the users\' experience. However, we are telling them something isn\'t working correctly and giving them a clear Retry button to attempt to get the app working again.\\n\\nIf the reason we\'re showing this to the user is because we can\'t load something non-critical, like the asset price history graph or their watchlist status, we shouldn\'t take down the entire screen. Hiding the current price of bitcoin and preventing the user from trading, just because we can\'t tell them whether bitcoin is on their watchlist, is a negative user experience.\\n\\nAnother negative of this UI is that it hides all app navigation from the user. Even if we have a good reason to show the user a full screen error, that doesn\'t mean we should hide the rest of the app in the process. A user should still be able to navigate to a different screen. In practice, we should only show users a \u201cfull screen error\u201d and not a \u201cfull app error\u201d.\\n\\n### Error Messages Everywhere\\n\\n<Image\\n  src={require(\'./images/2023-01-03-resilient-relay-apps-errors-everywhere.png\')}\\n  width=\\"35%\\"\\n  title=\\"Error Messages Everywhere\\"\\n/>\\n\\nThe UI pictured above is, in many ways, worse. This is the opposite end of the previous experience and showing the user a full-screen error would be preferable. Error messages for the price history graph make sense, because the user would expect that UI to be on this screen, but if the user can\'t even see the price of bitcoin or find the Trade button, we really ought to show them the UI in the first screenshot (but with navigation) - as the core goal and purpose of this screen has been lost.\\n\\nThis image also demonstrates how ErrorBoundaries can be too prevalent. The entire price history graph with the time range selectors should only have a single error message, not one per time range.\\n\\n### Empty Fallbacks\\n\\n<Image src={require(\'./images/2023-01-03-resilient-relay-apps-empty-fallbacks.png\')} width=\\"35%\\" title=\\"Empty Fallbacks\\" />\\n\\nThe UI above is just as bad as the example prior, In this case, our ErrorBoundaries fall back to empty content. For certain UI elements, this makes sense. The missing Share button next to the watchlist isn\'t critical for this UI, so omitting it makes sense. However, hiding the current price of bitcoin, the price history graph, and the Trade button makes the UI unusable and even somewhat misleading. Even users who don\'t use the app every day would know that something is off. We also aren\'t giving the user any option to retry any failures \u2014the user just sees empty content with no way to recover.\\n\\n### What should the user see instead?\\n\\nThe following two screenshots show an example of a better experience for the user. The first screenshot is what the user should see if we can\'t get the current price of bitcoin or if we can\'t determine whether the user is allowed to trade. The second screenshot would be a better experience for a user if we couldn\'t get the current change in the price of bitcoin or the price history.\\n\\n<div style={{ display: \'flex\', justifyContent: \'space-around\' }}>\\n  <Image\\n    src={require(\'./images/2023-01-03-resilient-relay-apps-full-screen-error.png\')}\\n    title=\\"Bummer, but at least I know something is wrong and can navigate to a different screen or try to refresh this screen.\\"\\n  />\\n  <Image\\n    src={require(\'./images/2023-01-03-resilient-relay-apps-missing-sparkline.png\')}\\n    title=\\"I wish I could see the price history, but at least I can still Trade or try to refresh the price history chart.\\"\\n  />\\n</div>\\n\\nAll of this points to a need to classify sections of the UI on a screen: what is critical for the user\'s experience, what UI the user expects to see, and what supporting content is optional to the experience.\\n\\n## Critical vs Expected vs Optional UI\\n\\nNot all UI elements in an application screen are the same. Some portions of the UI are critical to the core purpose of the screen, others might just be more informational and helpful to users. For application design at Coinbase, we group UI elements into three categories, **Critical**, **Expected**, and **Optional**.\\n\\n### Critical UI Elements\\n\\nThe parts of a screen that define the core information or interaction a user has with the UI. Without these elements in the UI, the screen does not make sense, and if they were missing, users would be confused and/or angry, as it isn\'t clear why the app wasn\'t working as expected.\\n\\nSuppose we can\'t load the data necessary to display these critical UI elements. In that case, we should show the user a full-screen error message explaining the problem (if possible) with a retry button that lets them easily attempt to re-request the missing data.\\n\\nLetting users interact with an application that is missing critical UI elements will cause confusion, anger, and even possible loss of funds if the user is able to complete a transaction without knowing the full details of what is happening.\\n\\nExamples of Critical UI elements:\\n\\n- The user\'s current portfolio balance on the Coinbase app home screen\\n- The Asset Price, Payment Method, and total Purchase Price on the order preview screen\\n- The user\'s lifetime earnings and earnings per asset on the Earn screen\\n\\n### Expected UI Elements\\n\\nExpected UI elements are the parts of a screen that might not serve the core purpose of a screen, but that most users would expect to be present. If Expected UI elements are missing from a screen, the user is likely to think that something is wrong, but this wouldn\'t prevent them from performing the core actions of the screen.\\n\\nIf we can\'t load the data necessary to display these expected UI elements, we should show the user a component-local error message telling them that there is an expected UI that is missing. These error messages should also be accompanied by a retry button to let the user re-request the missing data. Localized errors have a higher chance of not being seen or interacted with by the user, which is somewhat acceptable since they aren\'t required for the core purpose of the screen.\\n\\nLetting users interact with an application that is missing expected UI elements should be acceptable but it might cause confusion about what is happening. Completely omitting these UI elements without an accompanying error message would create a worse experience.\\n\\nExamples of Expected UI elements:\\n\\n- An asset\'s current price on the Buy Asset screen (where they enter the amount to buy)\\n- The price history graph on an asset detail screen\\n- A list of recent transactions on the Coinbase Card screen\\n\\n### Optional UI Elements\\n\\nOptional UI elements are the parts of a screen that are purely supportive to the main purpose of a screen. Some users might notice these missing elements, but others might be completely unaware that they\'re supposed to be present at all. In either scenario, a user wouldn\'t be prevented from accomplishing their main goal on the screen.\\n\\nIf we can\'t load the data necessary to display these Optional UI elements, we should instead just omit them entirely from the UI. However, this comes with the following risks:\\n\\nA. The user might not know that anything is missing\\nB. There won\'t be a way for the user to re-request the data for this UI unless they do a full screen refresh.\\n\\nDevelopers should consider these downsides and ensure that they do not cause a negative user experience. Instead, these failures should be logged so that product engineers are notified when the user experience is less than ideal.\\n\\nExamples of Optional UI Elements:\\n\\n- Offer cards on the asset detail screen\\n- Asset category sections on the Trade screen (New on Coinbase, Top Movers, etc.)\\n- News feed on the Home Screen\\n\\nLet\'s return to the image above and classify the sections of the UI into these categories.\\n\\n<Image\\n  src={require(\'./images/2023-01-03-resilient-relay-apps-sections.png\')}\\n  width=\\"35%\\"\\n  title=\\"Red: critical, Orange: expected, Yellow: optional\\"\\n/>\\n\\n### Element Classification Limits\\n\\nIn the example above, we have a screen that has two critical components, two expected components, and one optional component. Most screens in an app should only have a handful of critical UI components on them. For some screens, the entire UI might be composed of one single critical component.\\n\\nThe same is true for expected elements. If we have a screen that\'s composed of five separate expected UI elements, we\'d end up with the screenshot above with \u2018Try Again\' buttons littered across the app. Limit the number of expected elements and retry buttons on a single screen to only one or two if possible.\\n\\n### Pull To Refresh\\n\\nFor all of the above scenarios, users on mobile apps should be able to pull-to-refresh to retry any failed request on a screen. With Relay applications, this will usually mean retrying the full screen-level query. If a screen has any error messages or hidden components because of missing data, using pull-to-refresh should always attempt to fix all of those error conditions.\\n\\n### Work with your Product Managers and Designers\\n\\nAll of this classification is subjective \u2014 and all of the examples above are just one opinion and a designer or PM may have different opinions on how screens should degrade. It is important for cross-functional alignment when designing application UI. Teams should consult engineers, designers, and product managers to ensure seamless and on-brand screens across your entire app.\\n\\n## How Relay Can Help\\n\\nOnce you\'ve classified your screen into sections, the next step is to add the proper ErrorBoundaries to your app and configure your components\' GraphQL fragments depending on their classification. This is where [Relay](https://relay.dev) can help. Based on our experience working with Relay apps, we\'ve created several best practices around how to deal with missing data from GraphQL queries.\\n\\n### Background\\n\\nOur goal at Coinbase is to work with a nullable schema as [recommended by the Relay team](https://relay.dev/docs/guides/required-directive/#why-not-implement-this-at-the-schemaserver-level). The primary driver is that it puts the decision on how to handle service outages and missing query data in the hands of the client engineer. Without a nullable schema, the decision of what to do with missing data is made on the server (by bubbling up null values to the nearest nullable parent), and the client code has no recourse to change this decision.\\n\\nThis decision is buoyed by the existence of the [Relay `@required` directive](https://relay.dev/docs/guides/required-directive/), which allows client engineers to annotate their queries and fragments with directives that tell Relay how to handle missing data at runtime. This reduces boilerplate code that engineers would be required to write otherwise. On the surface, the directive seems very simple: it only comes with three options which are all pretty straightforward. However, when attempting to use this directive for various use cases, it becomes clear that the choice of which option to pick is not always obvious, nor is the decision of whether to use the directive at all.\\n\\n### Locality of @required\\n\\nOne great feature of the `@required` directive is that it only affects the fragment in which you use it. It will never change the behavior of other fragments that query the same field. This allows you to add or remove the directive without thinking about anything outside your component\'s scope. This is important because different components may be categorized differently, even if they get data from the same query. Being able to mark fields in fragments of the same query with different `@required` arguments is important to help build ideal user experiences.\\n\\n### Using action: LOG vs action: NONE\\n\\nThe `LOG` and `NONE` actions both have the same runtime behavior, but `LOG` will send a message to your logging mechanism of choice, logging the full path to the field that was returned as null. For most use cases where the `@required` directive is needed, `LOG` should be used over `NONE`. The only time `NONE` should be preferred is if a field is expected to be null for some users.\\n\\nWhile the log entry created by using `action: LOG` isn\'t likely to be actionable on its own, however, it can be a useful signal as a breadcrumb for future errors. Being able to look at the history of an error and see that a specific field was unexpectedly null can help track down future errors the user might encounter in a workflow.\\n\\n### When to use `@required(action:LOG/NONE)`\\n\\nThe `LOG/NONE` actions should only be used on fields which are necessary to display Optional UI in your components. There are two distinct use cases that this shows up when designing your application\\n\\n1. Your component is Optional UI and shouldn\'t be rendered at all if a field or set of fields is null\\n2. A portion of your component is Optional UI and relies on an object type field where that object makes no sense without one or more of its child fields\\n\\nLet\'s look at a fragment that encompasses both of these use cases:\\n\\n```graphql\\nfragment MyFragment on Asset {\\n  id\\n  name @required(action: LOG)\\n  slug @required(action: LOG)\\n  color\\n  supply {\\n    total @required(action: LOG)\\n    circulating @required(action: LOG)\\n  }\\n}\\n```\\n\\nFor this fragment, we\'re saying that the entire fragment is invalid if we don\'t get the name or slug fields. If those fields are returned from the server as null, we can\'t render this component at all. This fragment also shows how to use the `@required(action: LOG/NONE)` directive to invalidate an entire object type field. This fragment says that if we don\'t have either of the `supply.total` or `supply.circulating` fields, then the entire supply object is itself invalid and should be null. This nullability will then be used to hide an optional portion of this component\'s UI.\\n\\nNow let\'s see how our component will handle the results from this query:\\n\\n```tsx\\nconst asset = useFragment(\\n  graphql`\\n    fragment MyFragment on Asset {\\n      id\\n      name @required(action: LOG)\\n      slug @required(action: LOG)\\n      color\\n      supply {\\n        total @required(action: LOG)\\n        circulating @required(action: LOG)\\n      }\\n    }\\n  `,\\n  assetRef,\\n);\\n\\n// If we couldn\'t get the required asset name or slug fields, hide this entire UI\\nif (asset === null) {\\n  return null;\\n}\\n// Otherwise hide certain portions of the UI if data is missing\\nreturn (\\n  <>\\n    <Title color={asset.color}>{asset.name}</Title>\\n    <Subtitle>{asset.slug}</Subtitle>\\n    {asset.supply && (\\n      <SupplyStats total={asset.supply.total} circulating={asset.supply.circulating} />\\n    )}\\n  </>\\n);\\n```\\n\\nThe `@required` directive really shines here because it removes complex null checks that we\'d have to write otherwise. Instead of having to check whether both the `asset.name` or `asset.slug` fields are null, we can simply check if our entire fragment was nulled out and prevent rendering. The same is true when checking whether we should render the SupplyStats component. We only have to check whether the parent field is null in order to know that the two subfields are non-null.\\n\\n### When to use @required(action:THROW)\\n\\nUsing `@required(action: THROW)` is more straightforward. This action should be used on fields that are necessary to render your Expected or Critical UI component. If these fields are returned as null from the server, your component should throw an error to the nearest ErrorBoundary and the user should see an error message.\\n\\nHow far up the tree your ErrorBoundary is depends on how much of the UI you want to remove if there\'s an error. For example, if we\'re showing the user an error instead of an asset price history graph, it doesn\'t make sense to keep the time series buttons still in view, that entire UI should disappear as well. But we don\'t want to take out the entire screen if this happens either.\\n\\nMake sure your ErrorBoundary provides a mechanism for the user to retry the failed query to see if they can get the data on a subsequent attempt. We should always pair an error message with an actionable element to let the user recover. We shouldn\'t rely on the user being able (or knowing) to use the pull-to-refresh to reload the screen.\\n\\n#### A note about using @required(action: THROW) on fields in arrays\\n\\nYou should almost never use the `THROW` action in a component that selects both an array field and fields of that array. As an example of what not to do:\\n\\n```tsx\\nfunction Component({ assetPriceRef }) {\\n  const { quotes } = useFragment(\\n    graphql`\\n      fragment ComponentFragment on AssetPriceData {\\n        quotes {\\n          # Returns an array of items\\n          timestamp\\n          price @required(action: THROW)\\n        }\\n      }\\n    `,\\n    assetPriceRef,\\n  );\\n}\\n```\\n\\nThis component selects both the `quotes` array along with the `timestamp` and `price` fields on every item in that array. Putting `THROW` on the `quotes` field would be acceptable if we want to show the user an error if we don\'t get back any quotes. But, putting `THROW` on the `price` field would result in showing the user an error if even a single price field in that array was null. That\'s probably not the behavior we want. If we got back 23 of the 24 quotes for the past day correctly, we should probably still display the results we have and just omit the empty values instead.\\n\\nInstead, we should use `action: LOG/NONE` so that we only invalidate a single item in the array instead of all items. We can then optionally filter out the null values in the array if needed.\\n\\n```tsx\\nfunction Component({ assetPriceRef }) {\\n  const { quotes } = useFragment(\\n    graphql`\\n      fragment ComponentFragment on AssetPriceData {\\n        quotes {\\n          # Returns an array of items\\n          timestamp\\n          price @required(action: LOG)\\n        }\\n      }\\n    `,\\n    assetPriceRef,\\n  );\\n  const validQuotes = quotes.filter(removeNull);\\n}\\n```\\n\\n### When NOT to use @required on a field\\n\\nThe unhelpful answer to this question would be \u201cdon\'t use `@required` when a field isn\'t required\u201d. That answer trivializes the decision of what is required and what isn\'t when the answer is usually more nuanced, especially when your fragment has a dozen fields or more. However, we can follow a number of best practices to decide whether to mark a field as required or not. Again, it is important that you work with your PMs and Designers to help you with these decisions.\\n\\nThere is also a fine line between when to omit the `@required` directive vs using it with the `LOG/NONE` action. The primary difference is that you should omit the `@required` directive when the UI rendered by that field is Optional UI.\\n\\nSome components in your application can render a combination of different classifications of UI. For example, a single component might be responsible for displaying both the current price of an asset as well as what percent of users have bought or sold the asset over some time frame. This means the component is mixing both Critical UI (asset price) and Optional UI (buy/sell stats).\\n\\nIf a field is used to render optional content which can instead be omitted from the UI entirely without causing confusion for the user (remember, that\'s the definition of Optional UI) then you shouldn\'t use the `@required` directive on that field. Instead, you should add checks to your code to omit the UI if the field is null.\\n\\n```tsx\\nfunction SomeComponent({ queryRef }) {\\n  const { asset } = useFragment(\\n    graphql`\\n   asset {\\n     latestQuote @required(action: THROW) # Required data\\n     buyPercent  # Optional data\\n   }`,\\n    queryRef,\\n  );\\n\\n  return (\\n    <div>\\n      <div>Price: {asset.latestQuote}</div>\\n      {asset.buyPercent !== null && (\\n        <>\\n          <div>Buy Percent: {asset.buyPercent}</div>\\n          <div>Sell Percent: {1 - asset.buyPercent}</div>\\n        </>\\n      )}\\n    </div>\\n  );\\n}\\n```\\n\\nIn this example it would be incorrect to use `@required(action: LOG/NONE)` on the `buyPercent` field because that would invalidate the entire fragment which isn\'t the behavior we want.\\n\\nAnother less common use case of when to omit the `@required` directive is when you can provide a safe fallback value. Providing a fallback/default value for a field can be very dangerous if done incorrectly. While there are a few cases where it\'s potentially safe to fall back to a default value, it\'s generally pretty rare and should be avoided. However, if you can provide a safe fallback value, you should avoid adding `@required` to that field and instead use a fallback value.\\n\\nA couple of guidelines of when to provide a fallback value:\\n\\n- Fallback values for numeric fields (numbers or strings that represent numbers) should not be used.\\n  - Using a 0 in place of a missing value will always create more confusion for the user. Coinbase is a financial company and if we can\'t display accurate values to users, we shouldn\'t be displaying them at all. Showing a user that their account balance is $0.00 is clearly much worse than showing them an error message. That\'s an obvious use case, but even places such as the price change percent for an asset, APY% for Coinbase Card, or the amount a user can make via Coinbase Earn should never show 0 if we don\'t have the actual value.\\n- Fallback values for boolean fields should be used with caution.\\n  - The first choice for a fallback for boolean fields is usually to set the field to false. Depending on what the boolean field represents, falling back to false can create a worse customer experience than showing the user an error. Falling back to false for a field like `isEligibleForOffer` is probably acceptable because that is likely showing Optional content. Falling back to false for a field like `hasCoinbaseOneSubscription` would not be acceptable because for a user who is a CoinbaseOne subscriber the content is Expected and the user is going to be confused about why that UI is missing in the app\\n- Falling back to an empty array for array fields should be used with caution.\\n  - If you\'re showing the user their list of Coinbase Card transactions, falling back to an empty array is a bad idea, but if you\'re showing the user a list of recently added assets, it\'s probably okay to fallback to an empty array to omit the UI from displaying since the component is already doing to have to deal with the case of the array being empty.\\n- String fields should usually just deal with null instead.\\n  - In some cases, you might want to fallback to an empty string for string fields that are returned as null, but usually this creates the same code path if you just leave the field as null. Most string fields in a schema aren\'t expected to be empty so falling back to an empty string can create negative user experiences where the user will be shown an empty string instead of actual content.\\n\\n```tsx\\nfunction SomeComponent({ queryRef }) {\\n  const asset = useFragment(\\n    graphql`\\n      fragment MyFragment on Asset {\\n        canTrade @required(action: THROW) # Required data\\n        hasOfferToStake # Optional data\\n      }\\n    `,\\n    assetRef,\\n  );\\n\\n  const showStakeOffer = asset.hasOfferToStake ?? false;\\n\\n  return (\\n    <div>\\n      {asset.canTrade && <Button>Trade</Button>}\\n      {showStakeOffer && <Button>Stake your currency</Button>}\\n    </div>\\n  );\\n}\\n```\\n\\n## Summary\\n\\nIf you\'ve taken anything away from this document, hopefully, it\'s that a lot of thought needs to go into how to handle downtime and service interruptions. Handling failure states is an important part of building world-class applications. Make sure your design and PM team are on the same page with your team when scoping out new features. If they don\'t give you advice on what to show the user when data is missing, push back to come to a consensus as a team on these decisions.\\n\\nRelay can be a powerful tool in helping deal with application failures. Its granular ability to help you decide how to deal with failure might involve more work than you\'re used to. However, this extra effort pays off in the long run and goes a long way to improving customer experience with your applications."},{"id":"/2021/12/08/introducing-the-new-relay-compiler","metadata":{"permalink":"/relay/blog/2021/12/08/introducing-the-new-relay-compiler","source":"@site/blog/2021-12-08-introducing-the-new-relay-compiler.mdx","title":"Introducing the new Relay compiler","description":"Introducing the new Relay compiler","date":"2021-12-08T00:00:00.000Z","formattedDate":"December 8, 2021","tags":[{"label":"relay-compiler","permalink":"/relay/blog/tags/relay-compiler"},{"label":"rust","permalink":"/relay/blog/tags/rust"},{"label":"required","permalink":"/relay/blog/tags/required"}],"readingTime":11.185,"hasTruncateMarker":false,"authors":[{"name":"Robert Balicki, Tianyu Yao & Andrey Lunyov"}],"frontMatter":{"title":"Introducing the new Relay compiler","author":"Robert Balicki, Tianyu Yao & Andrey Lunyov","tags":["relay-compiler","rust","required"],"description":"Introducing the new Relay compiler","hide_table_of_contents":false},"prevItem":{"title":"Resilient Relay Applications","permalink":"/relay/blog/2023/01/03/resilient-relay-apps"},"nextItem":{"title":"Introducing Relay Hooks","permalink":"/relay/blog/2021/03/09/introducing-relay-hooks"}},"content":"import Image from \'@site/components/Image\';\\n\\nWe\'re extremely excited to release a preview of the new, Rust-based Relay compiler to open source today (as [`v13.0.0-rc.1`](https://github.com/facebook/relay/releases/tag/v13.0.0-rc.1))! This new compiler is faster, supports new runtime features, and provides a strong foundation for additional growth in the future.\\n\\nLeading up to this release, Meta\'s codebase had been growing without signs of stopping. At our scale, the time it took to compile all of the queries in our codebase was increasing at the direct expense of developer productivity. Though we tried a number of strategies to optimize our JavaScript-based compiler (discussed below), our ability to incrementally eke out performance gains could not keep up with the growth in the number of queries in our codebase.\\n\\nSo, we decided to rewrite the compiler in Rust. We chose Rust because it is fast, memory-safe, and makes it easy to safely share large data structures across threads. Development began in early 2020, and the compiler shipped internally at the end of that year. The rollout was smooth, with no interruptions to application development. Initial internal benchmarks indicated that the compiler performed nearly 5x better on average, and nearly 7x better at P95. We\'ve further improved the performance of the compiler since then.\\n\\nThis post will explore why Relay has a compiler, what we hope to unlock with the new compiler, its new features, and why we chose to use the Rust language. If you\'re in a hurry to get started using the new compiler, check out [the compiler package README](https://github.com/facebook/relay/tree/main/packages/relay-compiler) or the [release notes](https://github.com/facebook/relay/releases/tag/v13.0.0-rc.1) instead!\\n\\n## Why does Relay have a compiler?\\n\\nRelay has a compiler in order to provide stability guarantees and achieve great runtime performance.\\n\\nTo understand why, consider the workflow of using the framework. With Relay, developers use a declarative language called GraphQL to specify what data each component needs, but not how to get it. The compiler then stitches these components\' data dependencies into queries that fetch all of the data for a given page and precomputes artifacts that give Relay applications such a high level of performance and stability.\\n\\nIn this workflow, the compiler\\n\\n* allows components to be reasoned about in isolation, making large classes of bugs impossible, and\\n* shifts as much work as possible to build time, significantly improving the runtime performance of applications that use Relay.\\n\\nLet\'s interrogate each of these in turn.\\n\\n### Supporting local reasoning\\n\\nWith Relay, a component specifies only its own data requirements through the use of GraphQL fragments. The compiler then stitches these components data dependencies into queries that fetch all of the data for a given page. Developers can focus on writing a component without worrying how its data dependencies fit into a larger query.\\n\\nHowever, Relay takes this local reasoning a step further. The compiler also generates files that are used by the Relay runtime to read out just the data selected by a given component\'s fragment (we call this [data masking](https://relay.dev/docs/principles-and-architecture/thinking-in-relay/#data-masking)). So a component never accesses (in practice, not just at the type level!) any data that it didn\'t explicitly request.\\n\\nThus, modifying one component\'s data dependencies cannot affect the data another component sees, meaning that **developers can reason about components in isolation.** This gives Relay apps an unparalleled level of stability and makes large classes of bugs impossible, and is a key part of why Relay can scale to many developers touching the same codebase.\\n\\n### Improved runtime performance\\n\\nRelay also makes use of the compiler to shift as much work as possible to build time, improving the performance of Relay apps.\\n\\nBecause the Relay compiler has global knowledge of all components\' data dependencies, it is able to write queries that are as good \u2014 and generally even better \u2014 than they would be if they had been written by hand. It\'s able to do this by optimizing queries in ways that would be impractically slow at runtime. For example, it prunes branches that can never be accessed from the generated queries and flattens identical sections of queries.\\n\\nAnd because these queries are generated at build time, Relay applications never generate abstract syntax trees (ASTs) from GraphQL fragments, manipulate those ASTs, or generate query text at runtime. Instead, the Relay compiler replaces an application\'s GraphQL fragments with precomputed, optimized instructions (as plain ol\' Javascript data structures) that describe how to write network data to the store and read it back out.\\n\\nAn added benefit of this arrangement is that a Relay application bundle includes neither the schema nor \u2014 when using persisted queries \u2014 the string representation of the GraphQL fragments. This helps to reduce application size, saving users\' bandwidth and improving application performance.\\n\\nIn fact, the new compiler goes further and saves users\' bandwidth in another way \u2014 Relay can inform an application\'s server about each query text at build time and generate a unique query ID, meaning that the application never needs to send the potentially very long query string over users\' slow networks. When using such persisted queries, the only things that must be sent over the wire to make a network request are the query ID and the query variables!\\n\\n## What does the new compiler enable?\\n\\nCompiled languages are sometimes perceived as introducing friction and slowing developers down when compared to dynamic languages. However, Relay takes advantage of the compiler to reduce friction and make common developer tasks easier. For example, Relay exposes high-level primitives for common interactions that are easy to get subtly wrong, such as pagination and refetching a query with new variables.\\n\\nWhat these interactions have in common is that they require generating a new query from an old one, and thus involve boilerplate and duplication \u2014 an ideal target for automation. Relay takes advantage of the compiler\'s global knowledge to empower developers to enable pagination and refetching by adding one directive and changing one function call. That\'s it.\\n\\n**But giving developers the ability to easily add pagination is just the tip of the iceberg.** Our vision for the compiler is that it provides even more high-level tools for shipping features and avoiding boilerplate, gives developers real-time assistance and insights, and is made up of parts that can be used by other tools for working with GraphQL.\\n\\nA primary goal of this project was that the rewritten compiler\'s architecture should set us up to achieve this vision over the coming years.\\n\\nAnd while we\'re not there yet, we have made significant achievements on each of the criteria.\\n\\nFor example, the new compiler ships with support for the new `@required` directive, which will nullify the parent linked field or throw an error if a given subfield is null when read out. This may sound like a trivial quality-of-life improvement, but if half of your component\'s code is null checks, `@required` starts to look pretty good!\\n\\n:::note A component without `@required`\\n\\n<Image src={require(\'./images/2021-12-08-introducing-the-new-relay-compiler-pre-required.png\')} title=\\"A component with null-checking boilerplate\\"/>\\n\\n:::\\n\\n:::note And with `@required`:\\n\\n<Image src={require(\'./images/2021-12-08-introducing-the-new-relay-compiler-post-required.png\')} title=\\"A component will less null-checking boilerplate, due to the use of the `@required` directive\\"/>\\n\\n:::\\n\\n\\nNext, the compiler powers an internal-only VSCode extension that autocompletes field names when you type and shows type information on hover, among many other features. We haven\'t made it public, yet, but we hope to at some point! Our experience is that this VSCode extension makes working with GraphQL data much easier and more intuitive.\\n\\nLastly, the new compiler was written as a series of independent modules that can be reused by other GraphQL tools. We call this the Relay compiler platform. Internally, these modules are being reused for other code generation tools and for other GraphQL clients for different platforms.\\n\\n## Compiler performance\\n\\nSo far, we\'ve discussed why Relay has a compiler and what we hope the rewrite enables. But we haven\'t discussed why we decided to rewrite the compiler in 2020: performance.\\n\\nPrior to the decision to rewrite the compiler, the time it took to compile all of the queries in our codebase was gradually, but unrelentingly, slowing as our codebase grew. Our ability to eke out performance gains could not keep up with the growth in the number of queries in our codebase, and we saw no incremental way out of this predicament.\\n\\n### Reaching the end of JavaScript\\n\\nThe previous compiler was written in JavaScript. This was a natural choice of language for several reasons: it was the language with which our team had the most experience, the language in which the Relay runtime was written (allowing us to share code between the compiler and runtime), and the language in which the GraphQL reference implementation and our mobile GraphQL tools were written.\\n\\nThe compiler\'s performance remained reasonable for quite some time: Node/V8 comes with a heavily-optimized JIT compiler and garbage collector, and can be quite fast if you\'re careful (we were). But compilation times were growing.\\n\\nWe tried a number of strategies to keep up:\\n\\n* We had made the compiler incremental. In response to a change, it only recompiled the dependencies that were affected by that change.\\n* We had identified which transforms were slow (namely, flatten), and made the algorithmic improvements we could (such as adding memoization).\\n* The official `graphql` npm package\'s GraphQL schema representation took multiple gigabytes of memory to represent our schema, so we replaced it with a custom fork.\\n* We made profiler-guided micro-optimizations in our hottest code paths. For example, we stopped using the `...` operator to clone and modify objects, instead preferring to explicitly list out the properties of objects when copying them. This preserved the object\'s hidden class, and enabled the code to better JIT-optimized.\\n* We restructured the compiler to shell out to multiple workers, with each worker handling a single schema. Projects with multiple schemas are uncommon outside of Meta, so even with this, most users would have been using a single-threaded compiler.\\n\\nThese optimizations weren\'t enough to keep pace with the rapid internal adoption of Relay.\\n\\nThe biggest challenge was that NodeJS does not support multithreaded programs with shared memory. The best one can do is to start multiple workers that communicate by passing messages.\\n\\nThis works well in some scenarios. For example, Jest employs this pattern and makes use of all cores when running tests of transforming files. This is a good fit because Jest doesn\'t need to share much data or memory between processes.\\n\\nOn the other hand, our schema is simply too large to have multiple instances in memory, so there was simply no good way to efficiently parallelize the Relay compiler with more than one thread per schema in JavaScript.\\n\\n### Deciding on Rust\\n\\nAfter we decided to rewrite the compiler, we evaluated many languages to see which would meet the needs of our project. We wanted a language that was fast, memory-safe and supported concurrency \u2014 preferably with concurrency bugs caught at build time, not at runtime. At the same time we wanted a language that was well-supported internally. This narrowed it down to a few choices:\\n\\n* C++ met most of the criteria, but felt difficult to learn. And, the compiler doesn\'t assist with safety as much as we\'d like.\\n* Java was probably also a decent choice. It can be fast and is multi-core, but provides less low-level control.\\n* OCaml is a proven choice in the compiler space, but multi-threading is challenging.\\n* Rust is fast, memory-safe, and supports concurrency. It makes it easy to safely share large data structures across threads. With the general excitement around Rust, some previous experience on our team, and usage by other teams at Facebook, this was our clear top choice.\\n\\n## Internal rollout\\n\\nRust turned out to be a great fit! The team of mostly JavaScript developers found Rust easy to adopt. And, Rust\'s advanced type system caught many errors at build time, helping us maintain a high velocity.\\n\\nWe began development in early 2020, and rolled out the compiler internally at the end of that year. Initial internal benchmarks indicated that the compiler performed nearly 5x better on average, and nearly 7x better at P95. We\'ve further improved the performance of the compiler since then.\\n\\n## Release in OSS\\n\\nToday, we\'re excited to publish the new version of the compiler, as part of the Relay v13. New compiler features include:\\n\\n* [The `@required` directive.](https://relay.dev/docs/guides/required-directive/)\\n* The `@no_inline` directive, which can be used to prevent common fragments from being inlined, resulting in smaller generated files.\\n* Validation for conflicting GraphQL fields, arguments and directives\\n* [Support for TypeScript type generation](https://github.com/facebook/relay/pull/3182)\\n* Support for remote query persisting.\\n\\nYou can find more information about the compiler in the [README](https://github.com/facebook/relay/tree/main/packages/relay-compiler) and in the [release notes](https://github.com/facebook/relay/releases/tag/v13.0.0-rc.1)!\\n\\nWe\'re continuing to develop features within the compiler, such as giving developers the ability to access derived values on the graph, adding support for a more ergonomic syntax for updating local data, and fully fleshing out our VSCode extension, all of which we hope to release to open source. We\'re proud of this release, but there\'s still a lot more to come!\\n\\n## Thanks\\n\\nThank you Joe Savona, Lauren Tan, Jason Bonta and Jordan Eldredge for providing amazing feedback on this blog post. Thank you ch1ffa, robrichard, orta and sync for filing issues related to compiler bugs. Thank you to MaartenStaa for adding TypeScript support. Thank you @andrewingram for pointing out how difficult it is to enable the `@required` directive, which is now enabled by default. There are many others that contributed \u2014 this was truly a community effort!"},{"id":"/2021/03/09/introducing-relay-hooks","metadata":{"permalink":"/relay/blog/2021/03/09/introducing-relay-hooks","source":"@site/blog/2021-03-09-introducing-relay-hooks.md","title":"Introducing Relay Hooks","description":"Introducing Relay Hooks","date":"2021-03-09T00:00:00.000Z","formattedDate":"March 9, 2021","tags":[{"label":"relay-hooks","permalink":"/relay/blog/tags/relay-hooks"}],"readingTime":5.66,"hasTruncateMarker":false,"authors":[{"name":"Robert Balicki & Juan Tejada"}],"frontMatter":{"title":"Introducing Relay Hooks","author":"Robert Balicki & Juan Tejada","tags":["relay-hooks"],"description":"Introducing Relay Hooks","hide_table_of_contents":false},"prevItem":{"title":"Introducing the new Relay compiler","permalink":"/relay/blog/2021/12/08/introducing-the-new-relay-compiler"}},"content":"import useBaseUrl from \'@docusaurus/useBaseUrl\';\\n\\nWe are extremely excited to release [Relay Hooks](https://github.com/facebook/relay/releases/tag/v11.0.0), the most developer-friendly version of Relay yet, and [make it available to the OSS community](https://developers.facebook.com/blog/post/2021/03/09/introducing-relay-hooks-improved-react-apis-relay/) today! Relay Hooks is a set of new, rethought APIs for fetching and managing GraphQL data using React Hooks.\\n\\nThe new APIs are fully compatible with the existing, container-based APIs. Though we recommend writing any new code using Relay Hooks, *migrating existing containers to the new APIs is optional and container-based code will continue to work*.\\n\\nAlthough these APIs are newly released, they are not untested: the rewritten [Facebook.com](https://www.facebook.com) is entirely powered by Relay Hooks and these APIs have been the recommended way to use Relay at Facebook since mid-2019.\\n\\nIn addition, we are also releasing a rewritten <a href={useBaseUrl(\'/docs/guided-tour/\')}>guided tour</a> and <a href={useBaseUrl(\'/docs/\')}>updated documentation</a> that distill the best practices for building maintainable, data-driven applications that we have learned since first developing Relay.\\n\\nThough we still have a ways to go before getting started with Relay is as easy as we\u2019d like, we believe these steps will make the Relay developer experience substantially better.\\n\\n## What was released?\\n\\nWe released Relay Hooks, a set of React Hooks-based APIs for working with GraphQL data. We also took the opportunity to ship other improvements, like a more stable version of <a href={useBaseUrl(\'/docs/api-reference/fetch-query/\')}><code>fetchQuery</code></a> and the ability to customize object identifiers in Relay using <code>getDataID</code> (which is useful if your server does not have globally unique IDs.)\\n\\n See the [release notes](https://github.com/facebook/relay/releases/tag/v11.0.0) for a complete list of what was released.\\n\\n## What are the advantages of the Hooks APIs?\\n\\nThe newly released APIs improve the developer experience in at least the following ways:\\n\\n* The Hooks-based APIs for fetching queries, loading data with fragments, pagination, refetching, mutations and subscriptions generally require fewer lines of code and have less indirection than the equivalent container-based solution.\\n* These APIs have more complete Flow and Typescript coverage.\\n* These APIs take advantage of compiler features to automate error-prone tasks, such as the generation of refetch and pagination queries.\\n* These APIs come with the ability to configure fetch policies, which let you determine the conditions in which a query should be fulfilled from the store and in which a network request will be made.\\n* These APIs give you the ability to start fetching data before a component renders, something that could not be achieved with the container-based solutions. This allows data to be shown to users sooner.\\n\\nThe following examples demonstrate some of the advantages of the new APIs.\\n\\n## Refetching a fragment with different variables\\n\\nFirst, let\u2019s take a look at how we might refetch a fragment with different variables using the Hooks APIs:\\n\\n```js\\ntype Props = {\\n  comment: CommentBody_comment$key,\\n};\\n\\nfunction CommentBody(props: Props) {\\n  const [data, refetch] = useRefetchableFragment<CommentBodyRefetchQuery, _>(\\n    graphql`\\n      fragment CommentBody_comment on Comment\\n      @refetchable(queryName: \\"CommentBodyRefetchQuery\\") {\\n        body(lang: $lang) {\\n          text\\n        }\\n      }\\n    `,\\n    props.comment,\\n  );\\n\\n  return <>\\n    <CommentText text={data?.text} />\\n    <Button\\n      onClick={() =>\\n        refetch({ lang: \'SPANISH\' }, { fetchPolicy: \'store-or-network\' })\\n      }>\\n    >\\n      Translate\\n    </Button>\\n  </>\\n}\\n```\\n\\nCompare this to the equivalent [container-based example](https://gist.github.com/rbalicki2/2ac2829aefd8d032e8cb32cd0066bd4e). The Hooks-based example takes fewer lines, does not require the developer to manually write a refetch query, has the refetch variables type-checked and explicitly states that a network request should not be issued if the query can be fulfilled from data in the store.\\n\\n## Starting to fetch data before rendering a component\\n\\nThe new APIs allow developers to more quickly show content to users by starting to fetch data before a component renders. Prefetching data in this way is not possible with the container-based APIs. Consider the following example:\\n\\n```js\\nconst UserQuery = graphql`\\n  query UserLinkQuery($userId: ID!) {\\n    user(id: $userId) {\\n      user_details_blurb\\n    }\\n  }\\n`;\\n\\nfunction UserLink({ userId, userName }) {\\n  const [queryReference, loadQuery] = useQueryLoader(UserQuery);\\n\\n  const [isPopoverVisible, setIsPopoverVisible] = useState(false);\\n\\n  const maybePrefetchUserData = useCallback(() => {\\n    if (!queryReference) {\\n      // calling loadQuery will cause this component to re-render.\\n      // During that re-render, queryReference will be defined.\\n      loadQuery({ userId });\\n    }\\n  }, [queryReference, loadQuery]);\\n\\n  const showPopover = useCallback(() => {\\n    maybePrefetchUserData();\\n    setIsPopoverVisible(true);\\n  }, [maybePrefetchUserData, setIsPopoverVisible]);\\n\\n  return <>\\n    <Button\\n      onMouseOver={maybePrefetchUserData}\\n      onPress={showPopover}\\n    >\\n      {userName}\\n    </Button>\\n    {isPopoverVisible && queryReference && (\\n      <Popover>\\n        <React.Suspense fallback={<Glimmer />}>\\n          <UserPopoverContent queryRef={queryReference} />\\n        </React.Suspense>\\n      </Popover>\\n    )}\\n  </>\\n}\\n\\nfunction UserPopoverContent({queryRef}) {\\n  // The following call will Suspend if the request for the data is still\\n  // in flight:\\n  const data = usePreloadedQuery(UserQuery, queryRef);\\n  // ...\\n}\\n```\\n\\nIn this example, if the query cannot be fulfilled from data in the local cache, a network request is initiated when the user hovers over a button. When the button is finally pressed, the user will thus see content sooner.\\n\\nBy contrast, the container-based APIs initiate network requests when the component renders.\\n\\n### Hooks and Suspense for Data Fetching\\n\\nYou may have noticed that both of the examples use Suspense.\\n\\nAlthough Relay Hooks uses Suspense for some of its APIs, *support, general guidance, and requirements for usage of Suspense for Data Fetching in React are still* *not ready*, and the React team is still defining what this guidance will be for upcoming releases. There are some limitations when Suspense is used with React 17.\\n\\nNonetheless, we released Relay Hooks now because we know these APIs are on the right trajectory for supporting upcoming releases of React. Even though parts of Relay\u2019s Suspense implementation may still change, the Relay Hooks APIs themselves are stable; they have been widely adopted internally, and have been in use in production for over a year.\\n\\nSee <a href={useBaseUrl(\'/docs/migration-and-compatibility/suspense-compatibility/\')}>Suspense Compatibility</a> and <a href={useBaseUrl(\'/docs/guided-tour/rendering/loading-states/\')}>Loading States with Suspense</a> for deeper treatments of this topic.\\n\\n### Where to go from here\\n\\nPlease check out the <a href={useBaseUrl(\'/docs/\')}>getting started guide</a>, the <a href={useBaseUrl(\'/docs/migration-and-compatibility/\')}>migration guide</a> and the <a href={useBaseUrl(\'/docs/guided-tour/\')}>guided tour</a>.\\n\\n### Thanks\\n\\nReleasing Relay Hooks was not just the work of the React Data team. We\'d like to thank the contributors that helped make it possible:\\n\\n@0xflotus, @AbdouMoumen, @ahmadrasyidsalim, @alexdunne, @alloy, @andrehsu, @andrewkfiedler, @anikethsaha, @babangsund, @bart88, @bbenoist, @bigfootjon, @bondz, @BorisTB, @captbaritone, @cgriego, @chaytanyasinha, @ckknight, @clucasalcantara, @damassi, @Daniel15, @daniloab, @earvinLi, @EgorShum, @eliperkins, @enisdenjo, @etcinit, @fabriziocucci, @HeroicHitesh, @jaburx, @jamesgeorge007, @janicduplessis, @jaroslav-kubicek, @jaycenhorton, @jaylattice, @JonathanUsername, @jopara94, @jquense, @juffalow, @kafinsalim, @kyarik, @larsonjj, @leoasis, @leonardodino, @levibuzolic, @liamross, @lilianammmatos, @luansantosti, @MaartenStaa, @MahdiAbdi, @MajorBreakfast, @maraisr, @mariusschulz, @martinbooth, @merrywhether, @milosa, @mjm, @morrys, @morwalz, @mrtnzlml, @n1ru4l, @Nilomiranda, @omerzach, @orta, @pauloedurezende, @RDIL, @RicCu, @robrichard, @rsmelo92, @SeshanPillay25, @sibelius, @SiddharthSham, @stefanprobst, @sugarshin, @taion, @thedanielforum, @theill, @thicodes, @tmus, @TrySound, @VinceOPS, @visshaljagtap, @Vrq, @w01fgang, @wincent, @wongmjane, @wyattanderson, @xamgore, @yangshun, @ymittal, @zeyap, @zpao and @zth.\\n\\nThe open source project [`relay-hooks`](https://github.com/relay-tools/relay-hooks) allowed the community to experiment with Relay and React Hooks, and was a source of valuable feedback for us. The idea for the `useSubscription` hook originated in [an issue](https://github.com/relay-tools/relay-hooks/issues/5#issuecomment-603930570) on that repo. Thank you @morrys for driving this project and for playing such an important role in our open source community.\\n\\nThank you for helping make this possible!"}]}')}}]);